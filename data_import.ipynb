{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/nicksubic/Documents/flatiron/phase_1/nyc-mhtn-ds-091420-lectures/capstone/Clothing_Recommender/src/')\n",
    "sys.path.append('/Users/nicksubic/.wdm/drivers/chromedriver/mac64/87.0.4280.88/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Driver [/Users/nicksubic/.wdm/drivers/chromedriver/mac64/87.0.4280.88/chromedriver] found in cache\n",
      " \n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a \"base\" URL to append onto\n",
    "base_url = \"https://www.grailed.com/categories/tops\"\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "\n",
    "driver.get(base_url)\n",
    "timeout = 30\n",
    "\n",
    "try:\n",
    "    WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='feed-item']\")))\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timed out\")\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# skip elements at the top of the page\n",
    "results = driver.find_elements_by_xpath('//div[@class=\"FiltersInstantSearch\"]//div[@class=\"feed-item\"]')\n",
    "\n",
    "ScrollNumber=1\n",
    "\n",
    "# Start the scroll\n",
    "for i in range(0,ScrollNumber):\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# # Run again to see total number of results the scraper is going to get. Should be the same as ListingNumber above\n",
    "results = driver.find_elements_by_xpath('//div[@class=\"FiltersInstantSearch\"]//div[@class=\"feed-item\"]')\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(results):\n",
    "    ''''''\n",
    "\n",
    "    Name = []\n",
    "    Designer = []\n",
    "    Price = []\n",
    "    NewPrice = []\n",
    "    OldPrice = []\n",
    "    Size = []\n",
    "    Time = []\n",
    "    LastBump = []\n",
    "    Link = []\n",
    "    Image = []\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "\n",
    "        Designer.append(result.find_element_by_class_name(\"listing-designer\").text)\n",
    "        Name.append(result.find_element_by_class_name(\"listing-title\").text)\n",
    "        \n",
    "        try:\n",
    "            Price.append(result.find_element_by_xpath('.//p[@class=\"sub-title original-price\"]').text)\n",
    "            NewPrice.append(np.nan)\n",
    "            OldPrice.append(np.nan)\n",
    "        except NoSuchElementException:\n",
    "            NewPrice.append(result.find_element_by_xpath('.//p[@class=\"sub-title new-price\"]').text)\n",
    "            OldPrice.append(result.find_element_by_xpath('.//p[@class=\"sub-title original-price strike-through\"]').text)\n",
    "            Price.append(np.nan)\n",
    "\n",
    "        Size.append(result.find_element_by_xpath('.//p[@class=\"listing-size sub-title\"]').text)\n",
    "\n",
    "        Time.append(result.find_element_by_xpath(\".//span[@class='date-ago']\").text)\n",
    "\n",
    "        try:\n",
    "            LastBump.append(result.find_element_by_xpath(\".//span[@class='strike-through']\").text)\n",
    "        except NoSuchElementException:\n",
    "            LastBump.append(np.nan)\n",
    "\n",
    "        Link.append(result.find_element_by_xpath('./a').get_attribute(\"href\"))\n",
    "\n",
    "        grailed_dict = {'Name': Name, \n",
    "                    'Designer': Designer, \n",
    "                    'Price': Price, \n",
    "                    'NewPrice': NewPrice, \n",
    "                    'OldPrice': OldPrice, \n",
    "                    'Size': Size, \n",
    "                    'Time': Time, \n",
    "                    'LastBump': LastBump, \n",
    "                    'Link': Link}\n",
    "    return pd.DataFrame(grailed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_dataframe(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "imgurl= []\n",
    "for result in results:\n",
    "    images.append(result.find_element_by_xpath('//div[@class=\"listing-cover-photo \"]//div[@class=\"lazyload-wrapper\"]/img'))\n",
    "# for image in images:\n",
    "#     imgurl.append(image.get_attribute(\"src\"))\n",
    "# for image in images:\n",
    "#     print(image.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "# imgurl= []\n",
    "# for result in results:\n",
    "#     images.append(result.find_elements_by_css_selector(By.TAG_NAME, 'img'))\n",
    "# for image in images:\n",
    "#     imgurl.append(image.get_attribute(\"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = result.find_element_by_xpath('//div[@class=\"listing-cover-photo \"]//div[@class=\"lazyload-wrapper\"]//img').get_attribute(\"src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for result in results:\n",
    "#     images = result.find_elements_by_xpath('//div[@class=\"listing-cover-photo \"]')\n",
    "# # # image = results.find_element_by_tag_name(\"img\")\n",
    "# src = []\n",
    "# for image in images:\n",
    "#     src.append(image.find_element_by_tag_name('img'))\n",
    "#     # for i, url in enumerate(src):\n",
    "    #     urllib.request.urlretrieve(url, f'src/images/{i}.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options.add_argument('--headless')\n",
    "# driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Lists to append everything to\n",
    "UserName=[]\n",
    "Sold=[]\n",
    "Feedback=[]\n",
    "CurrentListings=[]\n",
    "Description=[]\n",
    "ProfileLink=[]\n",
    "FeedBack=[]\n",
    "FeedbackLink=[]\n",
    "FollowerCount=[]\n",
    "FullSize=[]\n",
    "PostedTime=[]\n",
    "BumpedTime=[]\n",
    "Location=[]\n",
    "Transactions=[]\n",
    "\n",
    "### Start Process. Link is a list of links from ItemDF\n",
    "for i, link in enumerate(df.Link):\n",
    "\n",
    "    driver.get(link)\n",
    "\n",
    "    image = driver.find_element_by_xpath('//div[@class=\"-image-wrapper\"]')\n",
    "    src = image.find_element_by_tag_name('img').get_attribute('src')\n",
    "    urllib.request.urlretrieve(src, f'src/images/{i}.jpg')\n",
    "\n",
    "    try:\n",
    "        UserName.append(driver.find_element_by_xpath('//span[@class=\"-username\"]').text)\n",
    "    except NoSuchElementException:\n",
    "        UserName.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        Sold.append(driver.find_element_by_xpath('//a[@class=\"-link\"]/span[2]').text)\n",
    "    except NoSuchElementException:\n",
    "        Sold.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        FeedBack.append(driver.find_element_by_xpath('//span[@class=\"-feedback-count\"]').text)\n",
    "    except NoSuchElementException:\n",
    "        FeedBack.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        CurrentListings.append(driver.find_element_by_xpath('//a[@class=\"-for-sale-link\"]').text)\n",
    "    except NoSuchElementException:\n",
    "        CurrentListings.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        Description.append(driver.find_element_by_xpath('//div[@class=\"listing-description\"]').text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        ProfileLink.append(driver.find_element_by_xpath('//span[@class=\"Username\"]/a').get_attribute(\"href\"))\n",
    "    except NoSuchElementException:\n",
    "        ProfileLink.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        FeedbackLink.append(driver.find_element_by_xpath('//div[@class=\"-details\"]/a').get_attribute(\"href\"))\n",
    "    except NoSuchElementException:\n",
    "        FeedbackLink.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        FollowerCount.append(driver.find_element_by_xpath('//p[@class=\"-follower-count\"]').text)\n",
    "    except NoSuchElementException:\n",
    "        FollowerCount.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        FullSize.append(driver.find_element_by_xpath('//h2[@class=\"listing-size sub-title\"]').text)\n",
    "    except NoSuchElementException:\n",
    "        FullSize.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        PostedTime.append(driver.find_element_by_xpath('//div[@class=\"-metadata\"]/span[2]').text)\n",
    "    except NoSuchElementException:\n",
    "        PostedTime.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        BumpedTime.append(driver.find_element_by_xpath('//div[@class=\"-metadata\"]/span[4]').text)\n",
    "    except NoSuchElementException:\n",
    "        BumpedTime.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        Location.append(driver.find_element_by_xpath('//label[@class=\"--label\"]').text)\n",
    "    except NoSuchElementException:\n",
    "        Location.append(np.nan)\n",
    "\n",
    "    # image = driver.find_element_by_class_name(\"-image _selected\")\n",
    "    # src = image.get_attribute('src')\n",
    "    # urllib.request.urlretrieve(src, f'src/images/{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_dict = {'Username': UserName,'Sold': Sold,'Feedback': FeedBack,'CurrentListings': CurrentListings, 'Description': Description, 'ProfileLink': ProfileLink, 'FeedbackLink': FeedbackLink, 'FollowerCount': FollowerCount,'FullSize': FullSize,'PostedTime': PostedTime,'BumpedTime': BumpedTime, 'Location': Location}\n",
    "SellerDF = pd.DataFrame(page_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, SellerDF], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 80 entries, 0 to 79\nData columns (total 21 columns):\nName               80 non-null object\nDesigner           80 non-null object\nPrice              73 non-null object\nNewPrice           7 non-null object\nOldPrice           7 non-null object\nSize               80 non-null object\nTime               80 non-null object\nLastBump           4 non-null object\nLink               80 non-null object\nUsername           80 non-null object\nSold               80 non-null object\nFeedback           80 non-null object\nCurrentListings    80 non-null object\nDescription        80 non-null object\nProfileLink        80 non-null object\nFeedbackLink       80 non-null object\nFollowerCount      80 non-null object\nFullSize           80 non-null object\nPostedTime         80 non-null object\nBumpedTime         4 non-null object\nLocation           80 non-null object\ndtypes: object(21)\nmemory usage: 13.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ]
}